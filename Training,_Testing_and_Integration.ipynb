{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "5hYywmsn9MvB",
        "outputId": "d14b9d2a-a338-46f5-d3c8-98dc5bfc5f13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'num_classes' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0142d9af9f72>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_classes' is not defined"
          ]
        }
      ],
      "source": [
        "#Train and Test Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(128, activation=\"relu\")(x)\n",
        "predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "#train the model\n",
        "history = model.fit(train_data, train_labels, validation_data=(val_data, val_labels), epochs=10)\n",
        "\n",
        "#evaluate the model\n",
        "results = model.evaluate(test_data, test_labels)\n",
        "print(\"Test Loss, Test Accuracy:\", results)\n",
        "\n",
        "#save the model\n",
        "model.save(\"marine_animal_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Integrate list of Endangered/Extinct Marine Animals\n",
        "\n",
        "#load dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "wwf_data = pd.read_csv('/path_to_your_file/WWF list of endangered marine animals  - Sheet1.csv')\n",
        "\n",
        "# Inspect the dataset\n",
        "print(wwf_data.head())\n",
        "print(wwf_data.info())\n",
        "\n",
        "#preprocess data\n",
        "\n",
        "# Convert species names to lowercase for consistency\n",
        "wwf_data['species'] = wwf_data['species'].str.lower().str.strip()\n",
        "#check for missing values\n",
        "print(wwf_data.isnull().sum())\n",
        "#remove duplicates\n",
        "wwf_data = wwf_data.drop_duplicates(subset='species')\n",
        "\n",
        "#integrate with my predictions\n",
        "predicted_species = 'leatherback turtle'  # Example prediction\n",
        "\n",
        "# Look up the conservation status in the WWF dataset\n",
        "status = wwf_data[wwf_data['species'] == predicted_species]['status'].values\n",
        "\n",
        "if len(status) > 0:\n",
        "    print(f\"The species '{predicted_species}' is classified as: {status[0]}\")\n",
        "else:\n",
        "    print(f\"The species '{predicted_species}' is not in the WWF dataset.\")\n",
        "\n",
        "#automate integration for batch processing\n",
        "# Example: List of predicted species from your model\n",
        "predictions = ['leatherback turtle', 'blue whale', 'great white shark']\n",
        "\n",
        "# Match each prediction with its status\n",
        "for species in predictions:\n",
        "    status = wwf_data[wwf_data['species'] == species.lower().strip()]['status'].values\n",
        "    if len(status) > 0:\n",
        "        print(f\"The species '{species}' is classified as: {status[0]}\")\n",
        "    else:\n",
        "        print(f\"The species '{species}' is not in the WWF dataset.\")\n",
        "\n",
        "#handle missing or unmatched species\n",
        "if len(status) == 0:\n",
        "    status = \"Unknown\"\n",
        "\n",
        "#present results\n",
        "results = pd.DataFrame({\n",
        "    'Predicted Species': predictions,\n",
        "    'Conservation Status': [wwf_data[wwf_data['species'] == sp.lower().strip()]['status'].values[0] if len(wwf_data[wwf_data['species'] == sp.lower().strip()]) > 0 else 'Unknown' for sp in predictions]\n",
        "})\n",
        "\n",
        "print(results)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nHzIEixb-39p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}